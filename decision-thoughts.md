Rough thoughts on decisions for project

- Using MVC to separate concerns. I like the idea of controllers only worrying about HTTP stuff, error handling, etc, while models only worry about data fetching/manipulation.  
- Database schema. For now, I forgo attaching orders to audit, like an order initiated by an audit. This can be useful for tracing how often orders were made per audit. A higher ratio could indicate a more popular time of year, which would be cause to reach out to the merchandiser about upping their usual replenishment rates. Could also give us data about why orders are being made. These are nice to haves, and certainly add value for the business services. But, not mission critical. Forgoing for now, but may add later. 
    - No longer true. Orders are tied to audits, so we can never have more orders than audits in the current implementation.
- Orders as separate domain. Pro: Orders and grow independently from audits. Makes each one more testable. However, cross domain dependencies are apparent as audits create orders.
- Order creation in audits controller: Keeps audit creation atomic while order creation is an audit side effect. Though, this tight coupling could violate single responsibility if orders grow more complex.
    - It could be necessary to put the separate model calls into a transaction, so that way they either succeed or fail (with rollback) together.
- Product Threshold lookup in auditsModel: An argument could be made that this is ok, since audits are the only thing that checks or needs the threshold. However, this tight coupling would make things more tangled if other domains need the use of threshold lookup. At that point, it may make more sense to have product threshold have its own domain.
    - One way to decouple is extracting the threshold check into a service which holds all the business logic, and can be used in other controllers if needed.
- SKUs and Location not normalized: For a production environment, with multiple retailers and products, SKUs and Location should have their own tables so that we can centralize the values, maintaining integrity. However, I have not done that here so as to make querying simpler and more efficient. This works for such a small scale take home project.
- Direct Database Connection vs REST API: The C# app connects directly to PostgreSQL using Npgsql instead of calling the REST API. This avoids HTTP overhead and API dependencies, but bypasses API validation and business logic. It creates a separate data access path that must be maintained alongside the API. For integration/export scenarios, direct access is often acceptable, but it means the C# code must know the database schema and changes to it.
    - Changed to REST API: It made more sense to do that so I wasn’t repeating myself (queries) in the C# code. The API is already doing the work for me. This ended up being a simpler implementation then having to deal with the db connection in the C# code.
- In-Memory Data Transformation: All data is fetched into memory, then transformed using LINQ. This is simple and works well for small datasets, but can cause memory issues with large datasets. For scalability, consider streaming or pagination, but for typical accounting exports this approach is probably fine.
- Typescript might’ve been cool: Or just some way to establish the types of the JS objects. This would’ve been super helpful when storing the results of queries into objects, that way we know what kind of data we can expect in the front end code.
-  No auth: There is no api token when requests are made. Unsafe, but for the scope of the project, this made for simpler and quicker implementation and testing without having to worry about auth. In a prod environment, we would want to implement checks for an api token, ensure clients are sending the token with requests, and prompted to re-auth if not.
- CORS should be locked down. 